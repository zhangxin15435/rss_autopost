---
layout: post
title: "Context Engineering for AI Agents: Key Lessons from Manus"
date: 2025-07-22 09:43:47 +0000
author: "马侨仪"
tags: ["技术", "AI"]
categories: ["blog"]
description: "Context engineering is quickly emerging as one of the most critical disciplines in AI development, yet it remains a field still in its experimental ph..."
excerpt: "Context engineering is quickly emerging as one of the most critical disciplines ..."
published: true
---

Context engineering is quickly emerging as one of the most critical disciplines in AI development, yet it remains a field still in its experimental phase. Best practices are not yet codified, so a transparent look into a production system is invaluable.
The team at Manus AI recently published a post on their experiences building a real-world agent, offering significant insights gained from four complete framework rebuilds. These lessons provide a practical roadmap for anyone building production-level AI systems.
The Primary Metric: KV-Cache Hit Rate
While task success is a common goal, the Manus team emphasizes that the single most important metric for a production agent is its KV-cache hit rate. This is more than a simple performance optimization; it is a core architectural constraint that directly impacts economic viability.
In agentic systems, the input context grows substantially with each turn, while the output (the next action) remains short. Manus reports an average input-to-output token ratio of 100:1. This makes prefix caching essential. With cached tokens costing 10 times less than uncached ones ($0.30/MTok vs. $3.00/MTok), efficient caching is fundamental to a sustainable product.
This focus leads to three guiding principles for context design:

Stable Prefixes: Even a single token difference can invalidate the entire cache downstream. Avoid dynamic elements like timestamps in system prompts.
Append-Only Context: Never modify previous actions or observations. Ensure deterministic serialization (even JSON key ordering matters).
Explicit Cache Breakpoints: When manual cache management is required, carefully place breakpoints to account for cache expiration patterns.
This represents a shift in thinking: context engineering isn't just about what information to include, but how to structure it for maximum reusability.

The "Tool Explosion" Problem
As an agent's capabilities expand, so does its collection of tools. However, a larger toolkit can paradoxically make the agent less effective. Manus identifies this as the "tool explosion" problem, where an expanded action space leads the model to select suboptimal or inefficient paths.
Their solution is both elegant and effective: mask tool availability instead of removing tools from the context. By keeping tool definitions stable and using logit masking, they preserve cache coherence and gain fine-grained control over the agent's action space.
Memory Architecture: The File System as External Context
Even with large context windows, their limits become apparent in complex tasks. The Manus team’s solution is to treat the file system as the ultimate context: unlimited, persistent, and directly accessible by the agent. This allows for "recoverable compression," where information like a webpage's content can be offloaded from the prompt as long as a URL or file path allows the agent to restore it when needed.
Attention Management Through Recitation
One of the most novel insights from Manus involves manipulating the model's attention through recitation. Their agents create and continuously update a todo.md file. The purpose is not just organization; it is a deliberate technique to guide the model. By reciting objectives at the end of the context, the agent pushes the global plan into the model's most recent attention span, reducing goal drift on long tasks.
Error Handling as a Feature
A counterintuitive but powerful lesson is to keep error information in the context. Failed actions and stack traces provide crucial learning signals that help the model self-correct. Manus argues that error recovery is a clear indicator of advanced agentic behavior, a factor often overlooked in academic benchmarks.
Breaking Patterns: The Few-Shot Trap
While useful in many applications, extensive few-shot prompting can create harmful patterns in agentic systems. A model can fall into a "rhythm," repeating an action because it matches the context's pattern, not because it is optimal. The solution is structured variation: introducing controlled randomness in formatting and phrasing to break these emergent patterns.
The Meta-Lesson: An Experimental Science
Beyond any specific technique, the Manus experience shows that context engineering is fundamentally an experimental science. Their process involved rebuilding their framework four times, with each iteration yielding new insights. This underscores the current reality of the field: progress comes from methodical testing and refinement.
Implications for the Industry
Several broader lessons emerge from this work:
Performance First: Production engineering must prioritize cache efficiency and cost from day one.
Stability Over Flexibility: Consistent, predictable structures often outperform dynamic systems that break caching.
Design for Messiness: Real-world agent behavior includes errors and suboptimal paths, and the system must be designed for this reality.
Externalize Memory: Context windows, regardless of size, should be supplemented with external memory systems like the file system.
Structure is Attention: How information is structured is as important as what information is included.
Looking Forward
The experiences from Manus point toward context engineering evolving from an art into a more formal science. Their systematic approach provides a roadmap for the industry. Key areas for future development will include standardized metrics beyond task success, better architectures for managing large toolsets, and more sophisticated external memory systems.
The transition from AI demos to production-grade agents requires this kind of systematic thinking. The willingness of teams like Manus to share their insights accelerates the entire field's learning curve, offering a starting point to avoid common pitfalls. The future of AI agents will be built by those who understand these production realities. Context engineering may be experimental, but it is no longer optional.

Further Reading:
Original Manus blog post with detailed technical implementation
The field is young, the challenges are real, and the opportunities are enormous. The question isn't whether context engineering will become critical—it's whether you'll learn these lessons through experimentation or through others' experience.
